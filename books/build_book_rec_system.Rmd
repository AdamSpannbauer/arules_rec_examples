---
title: "Book recs"
author: "Me"
date: "`r Sys.Date()`"
output: html_document
---

Source: https://www.kaggle.com/datasets/jirakst/bookcrossing?select=BX-Users.csv

Download link: https://www.kaggle.com/datasets/jirakst/bookcrossing/download?datasetVersionNumber=1

* Download zip file
* Unzip
* Keep unzipped data files in a folder named `data` that's in the same folder as this Rmd file

```{r message=FALSE}
library(dplyr)
library(arules)
library(XML)
```

```{r}
clean_names <- function(df_names) {
  tolower(gsub(".", "_", df_names, fixed = TRUE))
}

decode_html_entity <- function(x) {
  x <- iconv(x, to = "ASCII//TRANSLIT")
  if (is.na(x) | nchar(x) == 0) return("")
  
  xmlValue(getNodeSet(htmlParse(x, asText = TRUE), "//p")[[1]])
}

decode_html_entities <- function(x) {
  vapply(x, decode_html_entity, character(1), USE.NAMES = FALSE)
}
```

* Read in all relevant data

```{r}
ratings <- read.csv("data/BX-Book-Ratings.csv", sep = ";")
names(ratings) <- clean_names(names(ratings))

dim(ratings)
names(ratings)
head(ratings, 3)
```

```{r}
books <- read.csv("data/BX-Books.csv", sep = ";")
names(books) <- clean_names(names(books))

# Convert HTML endcoded symbols (eg "&amp;" becomes "&")
books$book_title <- decode_html_entities(books$book_title)
books$book_author <- decode_html_entities(books$book_author)
books$publisher <- decode_html_entities(books$publisher)

dim(books)
names(books)
head(books, 3)
```

```{r}
users <- read.csv("data/BX-Users.csv", sep = ";")
names(users) <- clean_names(names(users))

dim(users)
names(users)
head(users, 3)
```

* Following NPS rules; book must be rated 7 or above to be liked by user

```{r}
ratings <- ratings %>%
  filter(book_rating >= 7)
```

* Only keep books we have meta info on

```{r}
ratings <- ratings %>%
  filter(isbn %in% books$isbn)

books <- books %>%
  filter(isbn %in% ratings$isbn)
```

* De-duplicate books
  * Books will be unique based on title author combo
  * Some cases will still be duped; some note hard vs soft cover in title

```{r}
# Find first occurring isbn per title*author
std_isbns <- books %>%
  group_by(book_title, book_author) %>%
  summarise(std_isbn = head(isbn, 1))

# Make translation table holding original isbn
# and what std_isbn that maps to
isbn_translation <- books %>%
  left_join(std_isbns, by = c("book_title", "book_author")) %>%
  select(isbn, std_isbn)

# Convert map isbns in ratings to be std_isbn values
ratings <- ratings %>%
  left_join(isbn_translation, on = "isbn") %>%
  mutate(isbn = std_isbn) %>%
  select(-std_isbn)

# If a user rated same book across different isbns
# take average of different ratings
ratings <- ratings %>%
  group_by(user_id, isbn) %>%
  summarise(book_rating = mean(book_rating))

# Filter books to just those that appear in ratings
books <- books %>%
  filter(isbn %in% ratings$isbn)
```

* Only keep users who have rated at least `n` books
* Only keep books rated by at least `n` people
* These 2 are intertwined:
  * if BOOK_A is rated by only 2 users it stays, but 1 of its users only rated 1 book... so if I remove that user it lowers BOOK_A's ratings... if I remove BOOK_A it would lower some user's number of books rated.. ahhhhh

```{r}
min_book_ratings <- 2
min_user_ratings <- 2

done_filtering <- FALSE

while (!done_filtering) {
  drop_users <- ratings %>%
    group_by(user_id) %>%
    summarise(n = n()) %>%
    filter(n <= min_user_ratings) %>%
    pull(user_id) %>%
    unique()

  ratings <- ratings %>%
    filter(!(user_id %in% drop_users))

  drop_isbns <- ratings %>%
    group_by(isbn) %>%
    summarise(n = n()) %>%
    filter(n <= min_book_ratings) %>%
    pull(isbn) %>%
    unique()

  ratings <- ratings %>%
    filter(!(isbn %in% drop_isbns))

  if (length(drop_isbns) == 0 && length(drop_users) == 0) {
    done_filtering <- TRUE
  }
}

# Proving min rating reqs are met
sort(table(ratings$user_id))[1]
sort(table(ratings$isbn))[1]
```

* Filter additional data sets based on ratings filter

```{r}
books <- books %>%
  filter(isbn %in% ratings$isbn)

users <- users %>%
  filter(user_id %in% ratings$user_id)
```

* Find book popularity stats

```{r}
n_total_readers <- length(unique(ratings$user_id))

book_popularity <- ratings %>%
  group_by(isbn) %>%
  summarise(
    n_readers = n_distinct(user_id),
    avg_rating = mean(book_rating)
  ) %>%
  mutate(perc_readers = n_readers / n_total_readers) %>%
  left_join(books, by = "isbn") %>%
  arrange(-n_readers) %>%
  select(
    isbn, book_title, book_author,
    n_readers, perc_readers, avg_rating
  )

head(book_popularity)
```

* Convert to transactions

```{r}
book_transactions <- as(
  split(ratings$isbn, ratings$user_id),
  "transactions"
)
```

* summary stats

```{r}
n_books <- length(unique(ratings$isbn))
n_users <- length(unique(ratings$user_id))
n_ratings <- nrow(ratings)

cat(
  n_books, "  books\n",
  n_users, "  users\n",
  n_ratings, " n_ratings\n",
  sep = ""
)
```

* Save processed data files

```{r}
write.csv(
  book_popularity,
  file = "data/book_popularity.csv",
  row.names = FALSE
)

save(
  book_transactions,
  file = "data/book_transactions.Rdata"
)
```

* Inputs for recommendation

```{r}
# INPUTS
selected_books <- head(book_popularity)
selected_isbns <- sample(selected_books$isbn, 5)

min_len <- 2
min_confidence <- 0.1
min_support <- 2
max_time <- 0 # 0 disables time limit
```

```{r}
# RUNNING REC
# TODO:
too_popular <- character(0)

book_rules <- apriori(
  book_transactions,
  parameter = list(
    supp = min_support / length(book_transactions),
    conf = min_confidence,
    minlen = min_len,
    maxtime = max_time
  ),
  appearance = list(
    none = too_popular,
    lhs = selected_isbns,
    default = "rhs"
  ),
  control = list(
    verbose = FALSE
  )
)

if (length(book_rules) > 0) {
  book_rules <- book_rules[!is.redundant(book_rules)]
  book_rules <- book_rules[is.significant(book_rules, book_transactions)]

  recs_df <- DATAFRAME(
    book_rules,
    itemSep = " + ", setStart = "", setEnd = ""
  )

  recs_df <- recs_df %>%
    filter(!(RHS %in% selected_isbns)) %>%
    group_by(RHS) %>%
    summarise(confidence = max(confidence)) %>%
    rename(isbn = RHS) %>%
    arrange(-confidence) %>%
    left_join(book_popularity, by = "isbn")
} else {
  recs_df <- NULL
}

recs_df
```

